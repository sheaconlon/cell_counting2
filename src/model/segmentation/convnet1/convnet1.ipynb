{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure matplotlib.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our package.\n",
    "import sys, importlib\n",
    "sys.path.append(\"/home/ubuntu/cell_counting\")\n",
    "\n",
    "from src import dataset, visualization, preprocess, metric, losses\n",
    "from src.model import model\n",
    "from src.model import neural_net\n",
    "from src.model.segmentation.convnet1 import convnet1\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (if changes are made) Re-import our package.\n",
    "for module in (dataset, visualization, preprocess, metric, model, neural_net, convnet1, losses):\n",
    "    importlib.reload(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset, processing it as a collection of image-mask pairs.\n",
    "images_masks = dataset.Dataset(1)\n",
    "images_masks.load_image_mask_pairs(\"/home/ubuntu/cell_counting/data/easy/raw/images\",\n",
    "                                   \"/home/ubuntu/cell_counting/data/easy/raw/masks\", (2448*2, 2448*2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a batch.\n",
    "inputs, outputs = images_masks.get_batch(3)\n",
    "visualization.show_image_grid(inputs, 1, 3, 3, 10, \"images\")\n",
    "visualization.show_image_grid(outputs, 1, 3, 3, 10, \"masks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the images.\n",
    "#def normalize(batch):\n",
    "#    inputs, outputs = batch\n",
    "#    inputs = preprocess.smdm_normalize(inputs, 61, \"REFLECT\")\n",
    "#    return (inputs, outputs)\n",
    "#images_masks.map_batch(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a batch.\n",
    "#inputs, outputs = images_masks.get_batch(3)\n",
    "#visualization.show_image_grid(inputs, 1, 3, 2, 6, \"images\")\n",
    "#visualization.show_image_grid(outputs, 1, 3, 2, 6, \"masks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract patches from the images.\n",
    "def extract_patches(example):\n",
    "    input_, output = example\n",
    "    input_ = preprocess.extract_patches(input_, 61, 1000)\n",
    "    output = preprocess.extract_patches(output, 61, 1000)\n",
    "    examples = [(input_[i, ...] / 255, 0 if all(output[i, 61//2 + 1, 61//2 + 1] > 200) else 1) for i in range(input_.shape[0])]\n",
    "    return examples\n",
    "images_masks.map(extract_patches)\n",
    "images_masks.set_segment_size(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_masks._segment_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a batch.\n",
    "inputs, outputs = images_masks.get_batch(4*8)\n",
    "visualization.show_image_grid(inputs * 255, 4, 8, 2.5*4, 16, \"images\",\n",
    "                              [(\"colony\" if outputs[i] == 1 else \"not colony\") for i in range(outputs.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset.\n",
    "train, test = images_masks.split(0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the net.\n",
    "import tensorflow as tf\n",
    "net = convnet1.ConvNet1(\"saves/18-01-16-PM-09-07\", 120, train.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some metrics.\n",
    "train_data = train.get_batch(1000)\n",
    "test_data = test.get_batch(1000)\n",
    "def loss_fn(predicted, actual):\n",
    "    loss = tf.losses.softmax_cross_entropy(tf.one_hot(tf.cast(actual, tf.int32), 3), predicted)\n",
    "    with tf.Session().as_default():\n",
    "        return loss.eval()\n",
    "metrics = {\n",
    "    \"train_loss\": metric.LossMetric(train_data, loss_fn),\n",
    "    \"test_loss\": metric.LossMetric(test_data, loss_fn),\n",
    "    \"pred_thpt\": metric.PredictionThroughputMetric(test_data)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a function for plotting the metrics.\n",
    "def plot_metrics():\n",
    "    xs, ys = metrics[\"train_loss\"].get_results()\n",
    "    visualization.plot_line(xs, ys, \"Training Loss\", \"training examples seen\", \"cross-entropy loss on training data\",\n",
    "                            3, 10)\n",
    "    xs, ys = metrics[\"test_loss\"].get_results()\n",
    "    visualization.plot_line(xs, ys, \"Test Loss\", \"training examples seen\", \"cross-entropy loss on test data\", 3, 10)\n",
    "    xs, ys = metrics[\"pred_thpt\"].get_results()\n",
    "    visualization.plot_line(xs, ys, \"Training Throughput\", \"training examples seen\", \"speed of training in examples/s\",\n",
    "                            3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternately train and evaluate the net for 20 minutes.\n",
    "for _ in range(10):\n",
    "    net.train(train, 3*60)\n",
    "    net.evaluate(metrics)\n",
    "    display.clear_output()\n",
    "    plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternately train and evaluate the net for 20 minutes.\n",
    "for _ in range(10):\n",
    "    net.train(train, 3*60)\n",
    "    net.evaluate(metrics)\n",
    "    display.clear_output()\n",
    "    plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the dataset.\n",
    "microbia_segments.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
